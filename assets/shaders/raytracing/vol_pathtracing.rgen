#version 460

#extension GL_EXT_ray_tracing : require
#extension GL_EXT_debug_printf : enable
#extension GL_GOOGLE_include_directive : require

#include "../ubo/global_ubo.glsl"
#include "../common/ray.glsl"
#include "../common/payload.glsl"
#include "../common/random.glsl"
#include "../common/tone_mapping.glsl"
#include "../common/volume.glsl"
#include "sky.glsl"

// Min depth for Russian Roulette termination
#define RR_MIN_DEPTH 3

layout(location = PathTracePayloadLocation) rayPayloadEXT PathTracePayload p_pathTrace;

// Declare the top-level acceleration structure (TLAS)
layout(set = 1, binding = 0) uniform accelerationStructureEXT TLAS;

// Declare the output storage image
// The format qualifier (e.g., rgba8, rgba32f) should match how the image was created in Vulkan.
// rgba8 is common for 8-bit per channel normalized output. Use rgba32f for HDR float output.
layout(set = 3, binding = 0, rgba16f) uniform image2D outputImage;

Ray getCameraRay(uint seed) {
    // gl_LaunchIDEXT is the pixel coordinate (x, y, z) of the current invocation.
    const vec2 pixelCenter = vec2(gl_LaunchIDEXT.xy) + vec2(0.5);

    // gl_LaunchSizeEXT is the total number of ray generation invocations (width, height, depth).
    const vec2 imageDimensions = vec2(gl_LaunchSizeEXT.xy);

     // Normalized device coordinates (NDC), converted to [-1, 1] range (NDC space)
    const vec2 jitter = vec2(randomFloat(seed), randomFloat(seed)) - 0.5;
    const vec2 pixelPos = pixelCenter + jitter;
        
    // Normalized device coordinates
    const vec2 ndc = pixelPos / imageDimensions * 2.0 - 1.0;

    // Ray origin and direction in camera/view space
    // Assuming perspective projection
    const vec4 rayOriginView = vec4(0.0, 0.0, 0.0, 1.0);
    const vec4 rayTargetView = /*ubo.inverseProjectionMatrix*/ inverse(ubo.projectionMatrix) * vec4(ndc.x, ndc.y, 1.0, 1.0); 

    // Transform ray to world space
    Ray worldRay;
    // Camera position in world space
    worldRay.origin = (ubo.inverseViewMatrix * rayOriginView).xyz; 
    worldRay.direction = normalize((ubo.inverseViewMatrix * vec4(normalize(rayTargetView.xyz / rayTargetView.w), 0.0)).xyz);
    
    return worldRay;
}

void main()
{
    vec3 finalColor = vec3(0.0);

    const uint samplesPerPixel = 1;
    const int maxBounces = 4;

    for (uint currentSample = 0; currentSample < samplesPerPixel; ++currentSample) {
        uint seed = tea(gl_LaunchIDEXT.y * gl_LaunchSizeEXT.x + gl_LaunchIDEXT.x, uint(ubo.frameCount));

        Ray worldRay = getCameraRay(seed);

        p_pathTrace.radiance = vec3(0.0);
        p_pathTrace.throughput = vec3(1.0);
        p_pathTrace.origin = worldRay.origin;
        p_pathTrace.direction = worldRay.direction;
        p_pathTrace.depth = 0;
        p_pathTrace.done = false;
        p_pathTrace.seed = seed;
        p_pathTrace.isSpecularBounce = false;
        // TODO: set the medium index based on the volume the ray starts in
        p_pathTrace.mediumIndex = -1; // Assuming no medium at the start

        while (!p_pathTrace.done && p_pathTrace.depth < maxBounces) {
            traceRayEXT(
                TLAS,
                gl_RayFlagsOpaqueEXT,
                0xFF, 
                0, 0, 0,
                p_pathTrace.origin, 
                RAY_T_MIN,
                p_pathTrace.direction, 
                RAY_T_MAX,
                PathTracePayloadLocation
            );
            
            // Apply Russian Roulette Termination
            if (p_pathTrace.depth > RR_MIN_DEPTH) {
                // Calculate the Russian Roulette probability based on the max component of the throughput
                // to ensure that the path is terminated with a probability proportional to its contribution.
                float russianRouletteProbability = maxComponent(p_pathTrace.throughput);

                if (randomFloat(p_pathTrace.seed) > russianRouletteProbability) {
                    // if we need to terminate we go to the next sample
                    p_pathTrace.done = true;
                    break;
                }

                // Otherwise, we continue the path tracing with a reduced throughput
                p_pathTrace.throughput /= russianRouletteProbability;
            }
        }
        
        // we add the sample radiance to the final color
        finalColor += p_pathTrace.radiance;  
    }

    // then we average the final color by the number of samples
    finalColor /= samplesPerPixel;

    if (ubo.accumulationEnabled) {
        vec3 previousColor = imageLoad(outputImage, ivec2(gl_LaunchIDEXT.xy)).rgb;
        float weight = 1.0 / float(ubo.ptAccumulationCount + 1);
        finalColor = mix(previousColor, finalColor, weight);
    } 

    finalColor = saturate(finalColor);

    if (isnan(finalColor.r) || isnan(finalColor.g) || isnan(finalColor.b) ||
        isinf(finalColor.r) || isinf(finalColor.g) || isinf(finalColor.b)) {
        finalColor = vec3(1.0, 0.0, 1.0); // Magenta for error
    }
    
    imageStore(outputImage, ivec2(gl_LaunchIDEXT.xy), vec4(finalColor, 1.0));
}