#version 460

#extension GL_EXT_ray_tracing : require
#extension GL_EXT_debug_printf : enable
#extension GL_GOOGLE_include_directive : require

#include "../ubo/global_ubo.glsl"
#include "../common/ray.glsl"
#include "../common/payload.glsl"
#include "../common/random.glsl"
#include "../common/tone_mapping.glsl"
#include "../common/volume.glsl"
#include "sky.glsl"

// Min depth for Russian Roulette termination
#define RR_MIN_DEPTH 3

layout(location = PathTracePayloadLocation) rayPayloadEXT PathTracePayload p_pathTrace;
layout(location = DistancePayloadLocation) rayPayloadEXT float p_distance;

// Declare the top-level acceleration structure (TLAS)
layout(set = 1, binding = 0) uniform accelerationStructureEXT TLAS;

// Declare the output storage image
// The format qualifier (e.g., rgba8, rgba32f) should match how the image was created in Vulkan.
// rgba8 is common for 8-bit per channel normalized output. Use rgba32f for HDR float output.
layout(set = 3, binding = 0, rgba16f) uniform image2D outputImage;

layout(set = 8, binding = 0, std430) readonly buffer volumesSSBO {
    Volume volumes[]; 
} volumes;

Ray getCameraRay(uint seed) {
    // gl_LaunchIDEXT is the pixel coordinate (x, y, z) of the current invocation.
    const vec2 pixelCenter = vec2(gl_LaunchIDEXT.xy) + vec2(0.5);

    // gl_LaunchSizeEXT is the total number of ray generation invocations (width, height, depth).
    const vec2 imageDimensions = vec2(gl_LaunchSizeEXT.xy);

     // Normalized device coordinates (NDC), converted to [-1, 1] range (NDC space)
    const vec2 jitter = vec2(randomFloat(seed), randomFloat(seed)) - 0.5;
    const vec2 pixelPos = pixelCenter + jitter;
        
    // Normalized device coordinates
    const vec2 ndc = pixelPos / imageDimensions * 2.0 - 1.0;

    // Ray origin and direction in camera/view space
    // Assuming perspective projection
    const vec4 rayOriginView = vec4(0.0, 0.0, 0.0, 1.0);
    const vec4 rayTargetView = /*ubo.inverseProjectionMatrix*/ inverse(ubo.projectionMatrix) * vec4(ndc.x, ndc.y, 1.0, 1.0); 

    // Transform ray to world space
    Ray worldRay;
    // Camera position in world space
    worldRay.origin = (ubo.inverseViewMatrix * rayOriginView).xyz; 
    worldRay.direction = normalize((ubo.inverseViewMatrix * vec4(normalize(rayTargetView.xyz / rayTargetView.w), 0.0)).xyz);
    
    return worldRay;
}

void main()
{
    vec3 finalColor = vec3(0.0);

    const uint samplesPerPixel = 1;
    const int maxBounces = 4;

    for (uint currentSample = 0; currentSample < samplesPerPixel; ++currentSample) {
        uint seed = tea(gl_LaunchIDEXT.y * gl_LaunchSizeEXT.x + gl_LaunchIDEXT.x, uint(ubo.frameCount));

        Ray worldRay = getCameraRay(seed);

        p_pathTrace.radiance = vec3(0.0);
        p_pathTrace.throughput = vec3(1.0);
        p_pathTrace.origin = worldRay.origin;
        p_pathTrace.direction = worldRay.direction;
        p_pathTrace.depth = 0;
        p_pathTrace.done = false;
        p_pathTrace.seed = seed;
        p_pathTrace.isSpecularBounce = false;
        // TODO: set the medium index based on the volume the ray starts in
        p_pathTrace.mediumIndex = -1; // Assuming no medium at the start

        while (!p_pathTrace.done && p_pathTrace.depth < maxBounces) {
            // Query the distance to the nearest surface
            p_distance = 0.0;
            traceRayEXT(
                TLAS,
                gl_RayFlagsOpaqueEXT,
                0xFF, 
                2, 0, 2,
                p_pathTrace.origin, 
                RAY_T_MIN,
                p_pathTrace.direction, 
                RAY_T_MAX,
                DistancePayloadLocation
            );
            float t_hit = p_distance;

            // Sample the medium using Delta Tracking
            vec3 sigma_a = VOLUME_SIGMA_A;
            vec3 sigma_s = VOLUME_SIGMA_S;
            vec3 sigma_t = sigma_a + sigma_s;
            float sigma_t_maj = maxComponent(sigma_t); // Majorant extinction
            
            // describes the strength of the medium, higher means high probability of being
            // affected by the medium (so t_medium is the minimum distance to travel inside
            // the medium before interaction).
            float t_medium = -log(randomFloat(seed)) / sigma_t_maj;

            // Find ray segment inside the volume AABB
            vec2 volumeIntersectionInterval = intersectAABB(p_pathTrace.origin, p_pathTrace.direction, vec3(-0.5), vec3(0.5));

            const float t_entry = max(0.0, volumeIntersectionInterval.x);
            const float t_exit = volumeIntersectionInterval.y;

            float t_max_volume = min(t_hit, t_exit);
            
            //if (gl_LaunchIDEXT.x == 100 && gl_LaunchIDEXT.y == 100) {
                // Debugging output
            //    debugPrintfEXT("t_hit: %f, t_medium: %f, volumeIntersectionInterval: (%f, %f), t_max_volume: %f\n",
            //        t_hit, t_medium, volumeIntersectionInterval.x, volumeIntersectionInterval.y, t_max_volume);
            //}

            // Compare distances and decide event type
            // essentialy the t_medium < t_max_volume - volumeIntersectionInterval.x is a way to say:
            // "can the ray interact with the medium while passing through it? if the volume is dense or
            // high scattering, then t_medium is likely to be small, so the ray will interact with the medium
            // in a short distance from the nearest intersection point".
            if (t_entry < t_max_volume && t_medium < (t_max_volume - t_entry)) {
                // Volumetric Interaction Occurs
                
                // Advance ray to the interaction point (intersection point + t_medium)
                p_pathTrace.origin += p_pathTrace.direction * (t_entry + t_medium);
                
                // Real vs. Null Collision (using Woodcock tracking)

                // Assuming homogeneous for now - if heterogeneous:
                // - we have to obtain the current sigma_t of the medium at pointX 
                // - we then check if maxComponent(current_sigma_t(pointX)) / sigma_t_maj(pointX)
                vec3 current_sigma_t = sigma_t;

                // here we also account for the sum of scattering and absorption probabilities
                // (fine if not emissive volmus in the scene)
                // https://graphics.pixar.com/library/ProductionVolumeRendering/paper.pdf
                if (maxComponent(current_sigma_t) / sigma_t_maj > randomFloat(seed)) {
                    // It's a "real" collision

                    // Single Scattering Albedo. It is a common way to do Delta Tracking when
                    // emissive volumes are not present. Directly simulates the amount of light
                    // scattered by the medium at the point of interaction.
                    // https://graphics.pixar.com/library/ProductionVolumeRendering/paper.pdf (Section 2.1.1)
                    vec3 scatteringAlbedo = sigma_s / current_sigma_t;

                    p_pathTrace.isSpecularBounce = true;

                    // Update throughput with single scattering albedo
                    p_pathTrace.throughput *= scatteringAlbedo;
                    
                    // Sample new direction using phase function
                    p_pathTrace.direction = sampleHenyeyGreenstein(p_pathTrace.direction, VOLUME_PHASE_G, seed);
                    p_pathTrace.depth++;

                    // TODO: implement multiple importance sampling for multiple scattering volumes
                    // https://graphics.pixar.com/library/ProductionVolumeRendering/paper.pdf (section 4.2)

                }

                // If it's a null collision, we just continue without changing the direction or throughput.
                // we just changed the new origin to the point of interaction.

            } else {
                // Surface Interaction or No Interaction (miss)
                traceRayEXT(
                    TLAS,
                    gl_RayFlagsOpaqueEXT,
                    0xFF, 
                    0, 0, 0,
                    p_pathTrace.origin, 
                    RAY_T_MIN,
                    p_pathTrace.direction, 
                    t_hit + FLT_EPSILON,
                    PathTracePayloadLocation
                );                    
            }  

            // Apply Russian Roulette Termination
            if (p_pathTrace.depth > RR_MIN_DEPTH) {
                // Calculate the Russian Roulette probability based on the max component of the throughput
                // to ensure that the path is terminated with a probability proportional to its contribution.
                float russianRouletteProbability = maxComponent(p_pathTrace.throughput);

                if (randomFloat(p_pathTrace.seed) > russianRouletteProbability) {
                    // if we need to terminate we go to the next sample
                    p_pathTrace.done = true;
                    break;
                }

                // Otherwise, we continue the path tracing with a reduced throughput
                p_pathTrace.throughput /= russianRouletteProbability;
            }
        }
        
        // we add the sample radiance to the final color
        finalColor += p_pathTrace.radiance;  
    }

    // then we average the final color by the number of samples
    finalColor /= samplesPerPixel;

    if (ubo.accumulationEnabled) {
        vec3 previousColor = imageLoad(outputImage, ivec2(gl_LaunchIDEXT.xy)).rgb;
        float weight = 1.0 / float(ubo.ptAccumulationCount + 1);
        finalColor = mix(previousColor, finalColor, weight);
    } 

    finalColor = saturate(finalColor);

    if (isnan(finalColor.r) || isnan(finalColor.g) || isnan(finalColor.b) ||
        isinf(finalColor.r) || isinf(finalColor.g) || isinf(finalColor.b)) {
        finalColor = vec3(1.0, 0.0, 1.0); // Magenta for error
    }
    
    imageStore(outputImage, ivec2(gl_LaunchIDEXT.xy), vec4(finalColor, 1.0));
}