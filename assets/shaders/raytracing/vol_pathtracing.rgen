#version 460

#extension GL_EXT_ray_tracing : require
#extension GL_EXT_debug_printf : enable
#extension GL_GOOGLE_include_directive : require
#extension GL_EXT_nonuniform_qualifier : enable

#include "../ubo/global_ubo.glsl"
#include "../common/ray.glsl"
#include "../common/payload.glsl"
#include "../common/random.glsl"
#include "../common/tone_mapping.glsl"
#include "../common/volume.glsl"
#include "./common/push.glsl"
#include "sky.glsl"

// Min depth for Russian Roulette termination
#define RR_MIN_DEPTH 3

layout(location = PathTracePayloadLocation) rayPayloadEXT PathTracePayload p_pathTrace;
layout(location = DistancePayloadLocation) rayPayloadEXT float p_distance;

// Declare the top-level acceleration structure (TLAS)
layout(set = 1, binding = 0) uniform accelerationStructureEXT TLAS;

layout(set = 2, binding = 0) uniform sampler2D textures[];

// Declare the output storage image
// The format qualifier (e.g., rgba8, rgba32f) should match how the image was created in Vulkan.
// rgba8 is common for 8-bit per channel normalized output. Use rgba32f for HDR float output.
layout(set = 3, binding = 0, rgba16f) uniform image2D outputImage;

layout(set = 8, binding = 0, std430) readonly buffer volumesSSBO {
    Volume volumes[]; 
} volumes;

Ray getCameraRay(vec2 samplingNoise) {
    // gl_LaunchIDEXT is the pixel coordinate (x, y, z) of the current invocation.
    const vec2 pixelCenter = vec2(gl_LaunchIDEXT.xy) + vec2(0.5);

    // gl_LaunchSizeEXT is the total number of ray generation invocations (width, height, depth).
    const vec2 imageDimensions = vec2(gl_LaunchSizeEXT.xy);

     // Normalized device coordinates (NDC), converted to [-1, 1] range (NDC space)
    const vec2 jitter = samplingNoise - 0.5;
    const vec2 pixelPos = pixelCenter + jitter;
        
    // Normalized device coordinates
    const vec2 ndc = pixelPos / imageDimensions * 2.0 - 1.0;

    // Ray origin and direction in camera/view space
    // Assuming perspective projection
    const vec4 rayOriginView = vec4(0.0, 0.0, 0.0, 1.0);
    const vec4 rayTargetView = /*ubo.inverseProjectionMatrix*/ inverse(ubo.projectionMatrix) * vec4(ndc.x, ndc.y, 1.0, 1.0); 

    // Transform ray to world space
    Ray worldRay;
    // Camera position in world space
    worldRay.origin = (ubo.inverseViewMatrix * rayOriginView).xyz; 
    worldRay.direction = normalize((ubo.inverseViewMatrix * vec4(normalize(rayTargetView.xyz / rayTargetView.w), 0.0)).xyz);
    
    return worldRay;
}

/**
 * @brief Generates a random 2D blue noise value using a texture array.
 * 
 * The blue noise texture array is expected to be 64x64 pixels, with 64 different textures.
 * Each texture is used to animate the noise over time.
 * 
 * @param pixel The pixel coordinates (not UV) to sample from the blue noise texture.
 * @param frame The current frame index, used to select the appropriate texture slice.
 * @param blue_noise_texture_index The base index of the blue noise texture in the texture array.
 *
 * @return A float2 containing two [0..1] values sampled from the animated blue noise texture.
 *
 * @note Taken from https://github.com/JorenJoestar/DevGames2025/blob/main/source/shaders/devgames_2025/global.h
 */
vec2 animated_blue_noise(uvec2 pixel, uint frame, uint blue_noise_texture_index) {
    // Blue noise texture size is 128x128
    pixel = (pixel % 128);
    // There are 64 blue noise textures
    uint slice = (frame % 64);
    // Read blue noise from texture without filtering.
    // Adding non nearest/point filter is wrong.
    vec2 blue_noise = texture(textures[blue_noise_texture_index + slice], pixel).rg;
    
    return blue_noise;
}

void main()
{
    vec3 finalColor = vec3(0.0);

    const uint samplesPerPixel = 1;
    const int maxBounces = 5;

    for (uint currentSample = 0; currentSample < samplesPerPixel; ++currentSample) {
        // for random operations
        uint seed = tea(
            tea(gl_LaunchIDEXT.x, gl_LaunchIDEXT.y),
            tea(uint(ubo.frameCount), currentSample)
        );

        vec2 samplingNoise = vec2(0.0);

        if (push.noiseType == 0) {
            samplingNoise = randomVec2(seed);
        } else if (push.noiseType == 1) {
            // Use blue noise for sampling
            samplingNoise = animated_blue_noise(gl_LaunchIDEXT.xy, ubo.frameCount, push.blueNoiseBaseIndex);
        }

        Ray worldRay = getCameraRay(samplingNoise);

        p_pathTrace.radiance = vec3(0.0);
        p_pathTrace.throughput = vec3(1.0);
        p_pathTrace.origin = worldRay.origin;
        p_pathTrace.direction = worldRay.direction;
        p_pathTrace.depth = 0;
        p_pathTrace.done = false;
        p_pathTrace.seed = seed;
        p_pathTrace.samplingNoise = samplingNoise;
        p_pathTrace.isSpecularBounce = false;

        // TODO: set the medium index based on the volume the ray starts in
        // Assume camera starts in a vacuum. A more complex scene might require
        // a point-in-mesh test to determine if the camera is inside a volume.
        p_pathTrace.mediumIndex = -1; // Assuming no medium at the start

        while (!p_pathTrace.done && p_pathTrace.depth < maxBounces) {

            // We're currently in vacuum, so we simply trace the ray to find the nearest surface.
            if (p_pathTrace.mediumIndex == -1) {
                 traceRayEXT(
                    TLAS,
                    gl_RayFlagsOpaqueEXT,
                    0xFF, 
                    0, 0, 0,
                    p_pathTrace.origin, 
                    RAY_T_MIN,
                    p_pathTrace.direction, 
                    RAY_T_MAX,
                    PathTracePayloadLocation
                );  
            }

            // We're inside a medium, perform Delta Tracking (Woodcock Tracking)
            else {
                // Find distance to the next surface. This is our maximum travel distance.
                p_distance = 0.0;
                traceRayEXT(
                    TLAS,
                    gl_RayFlagsOpaqueEXT,
                    0xFF, 
                    2, 0, 2,
                    p_pathTrace.origin, 
                    RAY_T_MIN,
                    p_pathTrace.direction, 
                    RAY_T_MAX,
                    DistancePayloadLocation
                );
                float t_hit = p_distance;

                // Sample the current medium
                Volume currentVolume = volumes.volumes[p_pathTrace.mediumIndex];

                vec3 sigma_a = currentVolume.absorption.rgb;
                vec3 sigma_s = currentVolume.scattering.rgb;
                vec3 sigma_t = sigma_a + sigma_s;
                float sigma_t_maj = maxComponent(sigma_t);

                float phaseFunctionG = currentVolume.phaseFunctionG;

                //if (gl_LaunchIDEXT.x == 100 && gl_LaunchIDEXT.y == 100) {
                //    debugPrintfEXT("%v3f, %v3f, %d\n", sigma_a, sigma_s, p_pathTrace.mediumIndex);
                //}

                float t_medium = RAY_T_MAX;

                // If the medium is not empty, we sample the distance to the next interaction point
                if (sigma_t_maj > 0.0f) {
                    // This is the distance to the next interaction point in the medium
                    t_medium = -log(randomFloat(p_pathTrace.seed)) / sigma_t_maj;
                }

                // Compare the distances to decide the next volume event
                if (t_medium < t_hit) {
                    // Volumetric interaction occurs (real or null collision)

                    // Advance ray to the interaction point (origin + direction * t_medium)
                    p_pathTrace.origin += p_pathTrace.direction * t_medium;

                    // Assuming homogeneous for now - if heterogeneous:
                    // - we have to obtain the current sigma_t of the medium at pointX 
                    // - we then check if maxComponent(current_sigma_t(pointX)) / sigma_t_maj(pointX)
                    vec3 current_sigma_t = sigma_t;

                    // Use Woodcock tracking (null-scattering) to decide if it's a real event.
                    // For heterogeneous media, you'd sample density at the new origin.
                    if (maxComponent(current_sigma_t) / sigma_t_maj > randomFloat(p_pathTrace.seed)) {
                        // It's a "real" scattering event.

                        // Single Scattering Albedo. It is a common way to do Delta Tracking when
                        // emissive volumes are not present. Directly simulates the amount of light
                        // scattered by the medium at the point of interaction.
                        // https://graphics.pixar.com/library/ProductionVolumeRendering/paper.pdf (Section 2.1.1)
                        vec3 scatteringAlbedo = sigma_s / current_sigma_t;

                        // Sample new direction using phase function
                        vec3 newDirection = sampleHenyeyGreenstein(p_pathTrace.direction, phaseFunctionG, p_pathTrace.seed);
                    
                        // calculate the angle between the old and new direction
                        float cosTheta = dot(p_pathTrace.direction, newDirection);

                        // Then evaluate the phase function PDF value (prob of choosing that direction)
                        float phaseFunctionPDF = evalHenyeyGreenstein(cosTheta, phaseFunctionG);

                        // TODO: implement multiple importance sampling for multiple scattering volumes
                        // https://graphics.pixar.com/library/ProductionVolumeRendering/paper.pdf (section 4.2)   

                        // Update throughput
                        if (phaseFunctionPDF > 0.0) {
                            p_pathTrace.throughput *= scatteringAlbedo / phaseFunctionPDF;
                        }

                        p_pathTrace.direction = newDirection;
                        p_pathTrace.depth++;

                        // Treat volume scatter as "specular" to disable NEE on the next bounce
                        p_pathTrace.isSpecularBounce = true;
                    }
                    // (Else) If it's a null collision, we do nothing. The ray continues from the 
                    // new origin in the same direction, which is handled by the next loop iteration.

                } else {
                    // Surface Interaction or No Interaction (miss)
                    traceRayEXT(
                        TLAS,
                        gl_RayFlagsOpaqueEXT,
                        0xFF, 
                        0, 0, 0,
                        p_pathTrace.origin, 
                        RAY_T_MIN,
                        p_pathTrace.direction, 
                        t_hit + FLT_EPSILON,
                        PathTracePayloadLocation
                    );        
                }          
            }  

            // Apply Russian Roulette Termination
            if (p_pathTrace.depth >= RR_MIN_DEPTH) {
                // Calculate the Russian Roulette probability based on the max component of the throughput
                // to ensure that the path is terminated with a probability proportional to its contribution.
                float russianRouletteProbability = min(maxComponent(p_pathTrace.throughput), 0.95);

                if (randomFloat(p_pathTrace.seed) > russianRouletteProbability) {
                    // if we need to terminate we go to the next sample
                    p_pathTrace.done = true;
                    break;
                }

                // Otherwise, we continue the path tracing with a reduced throughput
                p_pathTrace.throughput /= russianRouletteProbability;
            }
        }
        
        // we add the sample radiance to the final color
        finalColor += p_pathTrace.radiance;  
    }

    // then we average the final color by the number of samples
    finalColor /= samplesPerPixel;

    /* Now accumulation is done inside denoising shaders
    if (ubo.accumulationEnabled) {
        vec3 previousColor = imageLoad(outputImage, ivec2(gl_LaunchIDEXT.xy)).rgb;          
        float weight = 1.0 / float(ubo.ptAccumulationCount + 1);
        finalColor = mix(previousColor, finalColor, weight);
    } */

    finalColor = saturate(finalColor);

    if (isnan(finalColor.r) || isnan(finalColor.g) || isnan(finalColor.b) ||
        isinf(finalColor.r) || isinf(finalColor.g) || isinf(finalColor.b)) {
        finalColor = vec3(1.0, 0.0, 1.0); // Magenta for error
    }
    
    imageStore(outputImage, ivec2(gl_LaunchIDEXT.xy), vec4(finalColor, 1.0));
}