#version 460

#extension GL_EXT_ray_tracing : require
#extension GL_EXT_debug_printf : enable
#extension GL_GOOGLE_include_directive : require

#include "../ubo/global_ubo.glsl"
#include "../common/ray.glsl"
#include "../common/payload.glsl"
#include "../common/random.glsl"
#include "../common/tone_mapping.glsl"
#include "../common/volume.glsl"
#include "sky.glsl"

layout(location = PathTracePayloadLocation) rayPayloadEXT PathTracePayload p_pathTrace;
layout(location = DistancePayloadLocation) rayPayloadEXT float p_distance;

// Declare the top-level acceleration structure (TLAS)
layout(set = 1, binding = 0) uniform accelerationStructureEXT TLAS;

// Declare the output storage image
// The format qualifier (e.g., rgba8, rgba32f) should match how the image was created in Vulkan.
// rgba8 is common for 8-bit per channel normalized output. Use rgba32f for HDR float output.
layout(set = 3, binding = 0, rgba16f) uniform image2D outputImage;

Ray getCameraRay(uint seed) {
    // gl_LaunchIDEXT is the pixel coordinate (x, y, z) of the current invocation.
    const vec2 pixelCenter = vec2(gl_LaunchIDEXT.xy) + vec2(0.5);

    // gl_LaunchSizeEXT is the total number of ray generation invocations (width, height, depth).
    const vec2 imageDimensions = vec2(gl_LaunchSizeEXT.xy);

     // Normalized device coordinates (NDC), converted to [-1, 1] range (NDC space)
    const vec2 jitter = vec2(randomFloat(seed), randomFloat(seed)) - 0.5;
    const vec2 pixelPos = pixelCenter + jitter;
        
    // Normalized device coordinates
    const vec2 ndc = pixelPos / imageDimensions * 2.0 - 1.0;

    // Ray origin and direction in camera/view space
    // Assuming perspective projection
    const vec4 rayOriginView = vec4(0.0, 0.0, 0.0, 1.0);
    const vec4 rayTargetView = /*ubo.inverseProjectionMatrix*/ inverse(ubo.projectionMatrix) * vec4(ndc.x, ndc.y, 1.0, 1.0); 

    // Transform ray to world space
    Ray worldRay;
    // Camera position in world space
    worldRay.origin = (ubo.inverseViewMatrix * rayOriginView).xyz; 
    worldRay.direction = normalize((ubo.inverseViewMatrix * vec4(normalize(rayTargetView.xyz / rayTargetView.w), 0.0)).xyz);
    
    return worldRay;
}

void main()
{
    vec3 finalColor = vec3(0.0);

    const uint samplesPerPixel = 1;
    const int maxBounces = 4;

    for (uint currentSample = 0; currentSample < samplesPerPixel; ++currentSample) {
        uint seed = tea(gl_LaunchIDEXT.y * gl_LaunchSizeEXT.x + gl_LaunchIDEXT.x, uint(ubo.frameCount));

        Ray worldRay = getCameraRay(seed);

        p_pathTrace.radiance = vec3(0.0);
        p_pathTrace.throughput = vec3(1.0);
        p_pathTrace.origin = worldRay.origin;
        p_pathTrace.direction = worldRay.direction;
        p_pathTrace.depth = 0;
        p_pathTrace.done = false;
        p_pathTrace.seed = seed;
        p_pathTrace.isSpecularBounce = false;

        while (!p_pathTrace.done && p_pathTrace.depth < maxBounces) {

            // Query the distance to the nearest surface
            p_distance = 0.0;
            traceRayEXT(
                TLAS,
                gl_RayFlagsOpaqueEXT,
                0xFF, 
                2, 0, 2,
                p_pathTrace.origin, 
                RAY_T_MIN,
                p_pathTrace.direction, 
                RAY_T_MAX,
                DistancePayloadLocation
            );
            float t_hit = p_distance;

            // Sample the medium using Delta Tracking
            vec3 sigma_a = VOLUME_SIGMA_A;
            vec3 sigma_s = VOLUME_SIGMA_S;
            vec3 sigma_t = sigma_a + sigma_s;
            float sigma_t_maj = maxComponent(sigma_t); // Majorant extinction
            
            // describes the strength of the medium, higher means high probability of being
            // affected by the medium (so t_medium is the minimum distance to travel inside
            // the medium before interaction).
            float t_medium = -log(randomFloat(seed)) / sigma_t_maj;

            // Find ray segment inside the volume AABB
            vec2 volumeIntersectionInterval = intersectAABB(p_pathTrace.origin, p_pathTrace.direction, vec3(-1.2), vec3(1.2));
            float t_max_volume = min(t_hit, volumeIntersectionInterval.y);
            
            // Compare distances and decide event type
            // essentialy the t_medium < t_max_volume - volumeIntersectionInterval.x is a way to say:
            // "can the ray interact with the medium while passing through it? if the volume is dense or
            // high scattering, then t_medium is likely to be small, so the ray will interact with the medium
            // in a short distance from the nearest intersection point".
            if (volumeIntersectionInterval.x < t_max_volume && t_medium < (t_max_volume - volumeIntersectionInterval.x)) {
                // Volumetric Interaction Occurs
                
                // Advance ray to the interaction point (intersection point + t_medium)
                p_pathTrace.origin += p_pathTrace.direction * (volumeIntersectionInterval.x + t_medium);
                
                // Real vs. Null Collision (using Woodcock tracking)
                vec3 current_sigma_t = sigma_t; // Assuming homogeneous for now
                if (maxComponent(current_sigma_t) / sigma_t_maj > randomFloat(seed)) {
                    // It's a "real" collision
                    vec3 scatteringAlbedo = sigma_s / current_sigma_t;

                    p_pathTrace.isSpecularBounce = true;

                    //TODO: probably to change is incorect
                    // Update throughput with scattering albedo
                    p_pathTrace.throughput *= scatteringAlbedo;
                    
                    // Sample new direction using phase function
                    p_pathTrace.direction = sampleHenyeyGreenstein(p_pathTrace.direction, VOLUME_PHASE_G, seed);
                    p_pathTrace.depth++;

                }

            } else {
                // Surface Interaction or No Interaction
                
                // No medium interaction happened in the segment. Attenuate by transmittance.
                // Note: In delta tracking, this is implicitly handled. If a collision was
                // sampled beyond t_hit, it means no collision happened. We don't need explicit
                // transmittance multiplication here because the sampling process itself accounts for it.
                
                if (t_hit < RAY_T_MAX) {
                     traceRayEXT(
                        TLAS,
                        gl_RayFlagsOpaqueEXT,
                        0xFF, 
                        0, 0, 0,
                        p_pathTrace.origin, 
                        RAY_T_MIN,
                        p_pathTrace.direction, 
                        t_hit + FLT_EPSILON,
                        PathTracePayloadLocation
                    );                    
                } 
            }            
        }
        
        finalColor += p_pathTrace.radiance;  
    }

    finalColor /= samplesPerPixel;

    if (ubo.accumulationEnabled) {
        vec3 previousColor = imageLoad(outputImage, ivec2(gl_LaunchIDEXT.xy)).rgb;
        float weight = 1.0 / float(ubo.ptAccumulationCount + 1);
        finalColor = mix(previousColor, finalColor, weight);
    } 

    finalColor = saturate(finalColor);

    if (isnan(finalColor.r) || isnan(finalColor.g) || isnan(finalColor.b) ||
        isinf(finalColor.r) || isinf(finalColor.g) || isinf(finalColor.b)) {
        finalColor = vec3(1.0, 0.0, 1.0); // Magenta for error
    }
    
    imageStore(outputImage, ivec2(gl_LaunchIDEXT.xy), vec4(finalColor, 1.0));
}